{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 4th of January 2024, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"0019-BYZ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_inversion` in order to produce samples from the below distribution using rejection sampling:\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-1}{e-1}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it times-out and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. *(There is a timeout decorator on this function and if it takes more than 10 seconds to generate 100000 samples it will timeout and it will count as if you failed to generate.)*\n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2e^{x^2} x}{e-1} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_inversion_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 1\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "def problem1_inversion(n_samples=1):\n",
    "    # Distribution from part 1\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "    problem1_samples = []\n",
    "\n",
    "    while len(problem1_samples) < n_samples:\n",
    "        x = np.random.uniform(0,1)       \n",
    "        # Calculate the probability of accepting the sample\n",
    "        f_x = (np.exp(x**2) / ((np.exp(1))-1))\n",
    "\n",
    "        # Use the next seed value for the acceptance check\n",
    "        u = np.random.uniform(0,1)  \n",
    "        # Increment the seed for the next iteration\n",
    "\n",
    "        # Accept the sample with probability f(x)/(M*g(x))\n",
    "        if u < f_x:\n",
    "            problem1_samples.append(x)\n",
    "    \n",
    "    return np.array(problem1_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/pnynpc9d6g141fp9hhncsc700000gn/T/ipykernel_1189/2862306407.py:7: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(problem1_samples, hist=True, kde=True,\n",
      "/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 2\n",
    "import numpy as np\n",
    "problem1_samples=problem1_inversion(n_samples=100000)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.hist(problem1_samples)\n",
    "sns.distplot(problem1_samples, hist=True, kde=True, \n",
    "             bins=int(100000/1000), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870520327235045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3\n",
    "import math\n",
    "import numpy as np\n",
    "'''\n",
    "Monte Carlo integration is a method for numerically estimating the value of an integral using \n",
    "random sampling. The basic idea is to approximate the integral by taking the average value of \n",
    "the integrand at randomly sampled points.\n",
    "'''\n",
    "def integrand(x):\n",
    "    return np.sin(x) * (2 * np.exp(x**2)*x / (np.exp(1) - 1))\n",
    "\n",
    "problem1_integral = np.mean(integrand(problem1_samples))\n",
    "problem1_integral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7827573386400372, 0.7913467268069719)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 4\n",
    "from numpy import *\n",
    "def hoeffding_interval(sample_mean, n, a, b, confidence_level=0.95):\n",
    "    epsilon = np.sqrt(np.log(2 / (1 - confidence_level)) / (2 * n))\n",
    "    return max(a, sample_mean - epsilon * (b - a)), min(b, sample_mean + epsilon * (b - a))\n",
    "a=0\n",
    "b=1\n",
    "n=len(problem1_samples)\n",
    "confidence_level=0.95\n",
    "problem1_interval = hoeffding_interval(problem1_integral, n, a, b, confidence_level)\n",
    "problem1_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "import random\n",
    "import numpy as np\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    # Distribution from part 2\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "    samples =[]\n",
    "    while len(samples) < n_samples:\n",
    "        u = np.random.uniform(0, 1)\n",
    "        x = np.random.uniform(0, 1/20)\n",
    "        fx = 20 * x * np.exp(-20 / x)\n",
    "        if u < fx:\n",
    "            samples.append(x)\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_inversion returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem2_X` which has shape (n_emails,3) where each feature in `problem2_X` corresponds to $X_1,X_2,X_3$ from above, `problem2_Y` which has shape **(n_emails,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [4p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [4p] Train the model `problem2_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem2_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem2_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem2_calibrator`.\n",
    "\n",
    "4. [3p] Use the trained model `problem2_ps` and the calibrator `problem2_calibrator` to make final predictions on the testing data, store the prediction in `problem2_final_predictions`. Compute the $0-1$ test-loss and store it in `problem2_01_loss` and provide a $99\\%$ confidence interval of it, store this in the variable `problem2_interval`, this should again be a tuple as in **problem1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_sms():\n",
    "    \"\"\"\n",
    "    A wrapper function to load the sms data\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    lines = []\n",
    "    hamspam = {'ham': 0, 'spam': 1}\n",
    "    with open('data/spam.csv', mode='r',encoding='latin-1') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # When using the csv reader, each time you use the function\n",
    "        # next on it, it will spit out a list split at the ','\n",
    "        header = next(reader)\n",
    "        # We store this as (\"txt\",label), where we have used the function\n",
    "        # hamspam to convert from \"ham\",\"spam\" to 0 and 1.\n",
    "        lines = [(line[1],hamspam[line[0]]) for line in reader]\n",
    "\n",
    "    return lines\n",
    "spam_no_spam =load_sms()\n",
    "x1=[]\n",
    "x2=[]\n",
    "x3=[]\n",
    "keywords = [\"free\", \"prize\", \"win\"]\n",
    "def getx(data,keyword):\n",
    "    x=[]\n",
    "    for sms, is_spam in spam_no_spam:\n",
    "        sms_lower = sms.lower()\n",
    "        has_keywords = keyword in sms_lower\n",
    "        if has_keywords:\n",
    "            x.append('1')\n",
    "        else:\n",
    "            x.append('0')\n",
    "    return x\n",
    "x1 = getx(spam_no_spam,\"free\")\n",
    "x2 = getx(spam_no_spam,\"prize\")\n",
    "x3 = getx(spam_no_spam,\"win\")\n",
    "problem2_X = np.array([x1,x2,x3],dtype='int').transpose()\n",
    "def gety(data):\n",
    "    y=[]\n",
    "    for sms, is_spam in data:\n",
    "        if is_spam:\n",
    "            y.append('1')\n",
    "        else:\n",
    "            y.append('0')\n",
    "    return y\n",
    "problem2_Y = np.array(gety(spam_no_spam),dtype='int')\n",
    "def train_test_validation(X,Y,test_size=0.4,validation_size=0.2,random_state=None,shuffle=True):\n",
    "    \"\"\"\n",
    "    Performs a train test validation split of the data [train_data,test_data,validation_data]\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : The input X, shape (n_samples,n_features)\n",
    "    Y : The input labells, shape (n_samples)\n",
    "    test_size : the proportion of data that should be test data\n",
    "    validation_size : the proportion of data that should be validation data\n",
    "    random_state : the random state variable passed through to sklearns train_test_split\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    X_train, X_test, X_valid, Y_train, Y_test, Y_valid\n",
    "\n",
    "    Examples:\n",
    "    ----------\n",
    "    >>> X_train, X_test, X_valid, Y_train, Y_test, Y_valid = train_test_validation(X,Y,test_size=0.25,validation_size=0.25)\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train,X_tt,Y_train,Y_tt = train_test_split(X,Y,\n",
    "                                                 test_size=test_size+validation_size,\n",
    "                                                 random_state=random_state,\n",
    "                                                 shuffle=shuffle)\n",
    "    X_test,X_valid,Y_test,Y_valid = train_test_split(X_tt,Y_tt,\n",
    "                                                     test_size=(validation_size)/(test_size + validation_size),\n",
    "                                                     random_state=random_state,\n",
    "                                                     shuffle=shuffle)\n",
    "\n",
    "    return X_train, X_test, X_valid, Y_train, Y_test, Y_valid\n",
    "problem2_X_train,problem2_X_test,problem2_X_calib,problem2_Y_train,problem2_Y_test,problem2_Y_calib = train_test_validation(problem2_X,problem2_Y,test_size = 0.4,validation_size = 0.2)\n",
    "print(problem2_X_train.shape,problem2_X_calib.shape,problem2_X_test.shape,problem2_Y_train.shape,problem2_Y_calib.shape,problem2_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        #cost = np.transpose(-y)@np.log(h) - np.transpose(1-y)@np.log(1-h) + (l/2)*np.transpose(t[1:])@t[1:]\n",
    "        #cost = (1/m)*cost\n",
    "        #return cost\n",
    "        lam = np.exp(np.dot(X, coeffs[:-1]) + coeffs[-1])\n",
    "        neg_log_likelihood = -np.sum(Y * np.log(lam) - lam)\n",
    "        return \n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "problem2_ps = ProportionalSpam()\n",
    "problem2_ps.fit(problem2_X_train, problem2_Y_train)\n",
    "problem2_X_pred = problem2_model.predict(problem2_X_calib).reshape(-1,1)\n",
    "problem2_calibrator = CalibratedClassifierCV(base_estimator=DecisionTreeClassifier(), method='sigmoid')\n",
    "problem2_calibrator.fit(problem2_X_pred, problem2_Y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "import scipy.stats as st\n",
    "problem2_final_predictions = problem2_calibrator.predict(problem2_ps.predict(problem2_X_test).reshape(-1, 1))\n",
    "problem2_01_loss = brier_score_loss(problem2_Y_test, problem2_final_predictions)\n",
    "alpha = 0.01\n",
    "n_test = len(problem2_Y_test)\n",
    "mean_loss = np.mean(problem2_01_loss)\n",
    "std_error = st.sem(problem2_01_loss)\n",
    "interval = st.t.interval(1 - alpha, n_test - 1, loc=mean_loss, scale=std_error)\n",
    "\n",
    "problem2_interval = interval\n",
    "\n",
    "# Print results\n",
    "print(f\"0-1 Test Loss: {problem2_01_loss}\")\n",
    "print(f\"99% Confidence Interval: {problem2_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Consider the following four Markov chains, answer each question for all chains:\n",
    "\n",
    "<img width=\"400px\" src=\"pictures/MarkovA.png\">Markov chain A</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovB.png\">Markov chain B</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovC.png\">Markov chain C</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovD.png\">Markov chain D</img>\n",
    "\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [2p] Is the Markov chain irreducible?\n",
    "3. [3p] Is the Markov chain aperiodic? What is the period for each state?\n",
    "4. [3p] Does the Markov chain have a stationary distribution, and if so, what is it?\n",
    "5. [3p] Is the Markov chain reversible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 1\n",
    "\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "import numpy as np\n",
    "\n",
    "problem3_A = np.array([[0.8, 0.2, 0.0, 0.0],\n",
    "              [0.6, 0.2, 0.2, 0.0],\n",
    "              [0.0, 0.4, 0.0, 0.6],\n",
    "              [0.0, 0.0, 0.8, 0.2]])\n",
    "problem3_B   = np.array([[0.0,0.2,0.0,0.8],\n",
    "                          [0.0,0.0,1.0,0.0],\n",
    "                          [0.0,1.0,0.0,0.0],\n",
    "                          [0.5,0.0,0.5,0.0]])\n",
    "problem3_C   = np.array([[0.2,0.3,0.0,0.0,0.5],\n",
    "                          [0.2,0.2,0.6,0.0,0.0],\n",
    "                          [0.0,0.4,0.0,0.6,0.0],\n",
    "                          [0.0,0.0,0.0,0.6,0.4],\n",
    "                          [0.0,0.0,0.0,0.4,0.6]])\n",
    "problem3_D   = np.array([[0.8,0.2,0.0,0.0],\n",
    "                          [0.6,0.2,0.2,0.0],\n",
    "                          [0.0,0.4,0.0,0.6],\n",
    "                          [0.1,0.0,0.7,0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "'''Irreducibility: a Markov chain is irreducible if its state space has only one connected class, \n",
    "i.e., the full membership of the state space,\n",
    "and the irreducibility of a Markov chain implies \n",
    "that the random variable can be transferred between any states during its evolution .'''\n",
    "problem3_A_irreducible = True\n",
    "problem3_B_irreducible = False\n",
    "problem3_C_irreducible = True\n",
    "problem3_D_irreducible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "# Answer each one with a True or False\n",
    "'''Non-periodic: an MC,there does not exist a state from which the length of time elapsed \n",
    "before returning to this state is periodic, \n",
    "Theorem: Irreducible and non-periodic finite state Markov chains with a unique smooth distribution.'''\n",
    "problem3_A_is_aperiodic = True\n",
    "problem3_B_is_aperiodic = False\n",
    "problem3_C_is_aperiodic = False\n",
    "problem3_D_is_aperiodic = True\n",
    "\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "\n",
    "problem3_A_periods = np.array([1,1,1,1])\n",
    "problem3_B_periods = np.array([1,1,1,1])\n",
    "problem3_C_periods = np.array([2,2,1,2,2])\n",
    "problem3_D_periods = np.array([2,2,2,2])\n",
    "#print(problem3_A_periods.shape)\n",
    "#print(problem3_B_periods.shape)\n",
    "#print(problem3_C_periods.shape)\n",
    "#print(problem3_D_periods.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 4\n",
    "import numpy as np\n",
    "def getstationary(P):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)  \n",
    "    stationary_distribution = np.real(eigenvectors[:, 0] / eigenvectors[:, 0].sum()) \n",
    "    answer_stationary = stationary_distribution\n",
    "    return answer_stationary\n",
    "def isver(P):\n",
    "    isnotinverse = 0\n",
    "    inverse =  1\n",
    "    import numpy as np\n",
    "    if np.linalg.det(P) == 0:\n",
    "        return isnotinverse\n",
    "    else:\n",
    "        return inverse\n",
    "#------------------------STATIONARY DISTRIBUTION-----------------\n",
    "# Answer each one with a True or False\n",
    "#A = isver(problem3_D)\n",
    "problem3_A_has_stationary = True\n",
    "problem3_B_has_stationary = True\n",
    "problem3_C_has_stationary = True\n",
    "problem3_D_has_stationary = True\n",
    "\n",
    "# Answer the following with the stationary distribution as a numpy array of shape (n_states,)\n",
    "# if the Markov chain has a stationary distribution otherwise answer with False\n",
    "#A = \n",
    "problem3_A_stationary_dist = getstationary(problem3_A)\n",
    "problem3_B_stationary_dist = getstationary(problem3_B)\n",
    "problem3_C_stationary_dist = getstationary(problem3_C)\n",
    "problem3_D_stationary_dist = getstationary(problem3_D)\n",
    "\n",
    "#print(problem3_A_stationary_dist.shape)\n",
    "#print(problem3_B_stationary_dist.shape)\n",
    "#print(problem3_C_stationary_dist.shape)\n",
    "#print(problem3_D_stationary_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 5\n",
    "#------------------------REVERSIBLE-----------------\n",
    "# Answer each one with a True or False\n",
    "'''The reversibility of a Markov chain is a stricter form of irreducibility,\n",
    "i.e., it not only transfers between arbitrary states, but also transfers to each state with equal probability, \n",
    "so that a reversible Markov chain is a sufficient non-necessary condition for a smooth Markov chain.'''\n",
    "problem3_A_is_reversible = False\n",
    "problem3_B_is_reversible = False\n",
    "problem3_C_is_reversible = False\n",
    "problem3_D_is_reversible = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
